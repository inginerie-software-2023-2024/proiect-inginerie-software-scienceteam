{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7156513,"sourceType":"datasetVersion","datasetId":4132976},{"sourceId":7186710,"sourceType":"datasetVersion","datasetId":4154818},{"sourceId":7191698,"sourceType":"datasetVersion","datasetId":4158530},{"sourceId":7203217,"sourceType":"datasetVersion","datasetId":4167003},{"sourceId":7239480,"sourceType":"datasetVersion","datasetId":4192855},{"sourceId":7241318,"sourceType":"datasetVersion","datasetId":4194157},{"sourceId":7244996,"sourceType":"datasetVersion","datasetId":4196785},{"sourceId":7248283,"sourceType":"datasetVersion","datasetId":4199245}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport sys\nimport tqdm\nimport cv2 as cv\nimport gc\nimport numpy as np\nimport torch\nfrom tqdm import tqdm","metadata":{"id":"Y6WtBJXuLrHM","execution":{"iopub.status.busy":"2023-12-22T00:30:07.689563Z","iopub.execute_input":"2023-12-22T00:30:07.690476Z","iopub.status.idle":"2023-12-22T00:30:11.674219Z","shell.execute_reply.started":"2023-12-22T00:30:07.690441Z","shell.execute_reply":"2023-12-22T00:30:11.672897Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install torcheval","metadata":{"execution":{"iopub.status.busy":"2023-12-22T00:30:11.676243Z","iopub.execute_input":"2023-12-22T00:30:11.676656Z","iopub.status.idle":"2023-12-22T00:30:26.166265Z","shell.execute_reply.started":"2023-12-22T00:30:11.676628Z","shell.execute_reply":"2023-12-22T00:30:26.165143Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting torcheval\n  Obtaining dependency information for torcheval from https://files.pythonhosted.org/packages/e4/de/e7abc784b00de9d05999657d29187f1f7a3406ed10ecaf164de06482608f/torcheval-0.0.7-py3-none-any.whl.metadata\n  Downloading torcheval-0.0.7-py3-none-any.whl.metadata (8.6 kB)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torcheval) (4.5.0)\nDownloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torcheval\nSuccessfully installed torcheval-0.0.7\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Single GPU Training","metadata":{}},{"cell_type":"code","source":"device = torch.device(f'cuda:0' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-12-22T00:30:26.167951Z","iopub.execute_input":"2023-12-22T00:30:26.168764Z","iopub.status.idle":"2023-12-22T00:30:26.199611Z","shell.execute_reply.started":"2023-12-22T00:30:26.168721Z","shell.execute_reply":"2023-12-22T00:30:26.198628Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport lzma\nimport tarfile\nfrom tqdm import tqdm\nimport os\nfrom torch import nn\nimport torch.distributed as dist\nimport torch.multiprocessing as mp\nfrom torch.utils.data.distributed import DistributedSampler\nfrom torch.nn.parallel import DistributedDataParallel as DDP\nimport torch.distributed as dist\nimport torch\nfrom tqdm.auto import tqdm\nfrom torch.optim.lr_scheduler import OneCycleLR\nfrom torch.utils.tensorboard import SummaryWriter\nimport warnings\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchvision.models as models\nimport tarfile\nimport lzma\nfrom tqdm import tqdm\nimport torch.multiprocessing as mp\nfrom torchvision import models\nimport torch.nn.functional as F\nimport torch\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms\nfrom PIL import Image\n\ndef get_data():\n    \n    train_files_names = []\n    with open('/kaggle/input/augmentare-1000-102-2/ip102_v1.1/train.txt','r') as f:\n        train_files_names = f.readlines()\n\n    val_files_names = []\n    with open('/kaggle/input/augmentare-1000-102-2/ip102_v1.1/val.txt','r') as f:\n        val_files_names = f.readlines()\n    with open('/kaggle/input/augmentare-1000-102-2/ip102_v1.1/test.txt','r') as f:\n        test_files_names = f.readlines()\n    \n    train_files_names = [x[:-1] for x in train_files_names]\n    train_files_names.sort()\n    \n    val_files_names = [x[:-1] for x in val_files_names]\n    val_files_names.sort()\n    \n    test_files_names = [x[:-1] for x in test_files_names]\n    test_files_names.sort()\n    \n    train_files = [x.split(' ')[0] for x in train_files_names]\n    train_labels = [int(x.split(' ')[1]) for x in train_files_names]\n    train_labels_pt = torch.tensor(train_labels)\n    \n    test_files = [x.split(' ')[0] for x in test_files_names]\n    test_labels = [int(x.split(' ')[1]) for x in test_files_names]\n    test_labels_pt = torch.tensor(test_labels)\n    \n    val_files = [x.split(' ')[0] for x in val_files_names]\n    val_labels = [int(x.split(' ')[1]) for x in val_files_names]\n    val_labels_pt = torch.tensor(val_labels)\n\n    directory = '/kaggle/input/augmentare-1000-102-2/ip102_v1.1/images/'\n    files = os.listdir(directory)\n    files.sort()\n    \n    train_images,val_images, test_images = [],[],[]\n    for file in tqdm(files):\n        if file in train_files:\n            train_images.append(directory+file)\n        elif file in val_files:\n            val_images.append(directory+file)\n        elif file in test_files:\n            test_images.append(directory+file)\n\n      \n\n    return train_images,val_images,train_labels,val_labels,train_labels_pt,val_labels_pt,test_images,test_labels,test_labels_pt\n\n\ndef class_weights(labels):\n    from collections import Counter\n    c = Counter(labels)\n    mc = c.most_common()\n    print(mc)\n    weights = []\n    total_samples = len(labels)\n    mc.sort(key=lambda x: x[0])\n    # option 1:\n    # nr of samples divided by the number of samples for each class\n    for i in range(len(mc)):\n        weights.append(total_samples/ mc[i][1])\n        \n    # option 2: 1-no_samples_per_class/total_samples\n    weights = torch.tensor(weights)\n    print(weights)\n    return weights\n\n\ndef get_criterion(weights):\n    \n    criterion = nn.CrossEntropyLoss(weight=weights,label_smoothing=0.3)\n    \n    return criterion\n\nimport torch\nimport torch.nn as nn\nimport torchvision.models as models\n\n\nclass CustomModel(nn.Module):\n    def __init__(self,sota):\n        super(CustomModel, self).__init__()\n        self.sota = sota\n        self.sota.classifier = nn.Sequential(\n            nn.Linear(960, 1280),  # Original first fully connected layer\n            nn.Hardswish(),\n            nn.Dropout(p=0.2, inplace=True),\n            nn.Linear(1280, 102)  # New fully connected layer with 256 output features\n        )\n        for name, param in self.sota.named_parameters():\n            if not name.startswith('features.16') and not name.startswith('classifier'):\n                param.requires_grad = False\n        for name, param in self.sota.named_parameters():\n            print(f'{name}: requires_grad={param.requires_grad}')\n        \n    def forward(self,x):\n        x = self.sota(x)\n        return  x\n\n\n\ndef get_model():\n    # Load the ResNet50 model\n    model = models.mobilenet_v3_large(weights='DEFAULT')\n\n    model = CustomModel(model)\n   \n    \n    return model\n\n\n\nclass CustomDataset(Dataset):\n    def __init__(self, image_list, label_list, transform=None):\n        self.image_list = image_list\n        self.label_list = label_list\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_list)\n\n    def __getitem__(self, idx):\n        image_path = self.image_list[idx]\n        label = self.label_list[idx]\n\n        # Load the image\n        image = Image.open(image_path).convert(\"RGB\")\n\n        # Apply transformations if any\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label\n\n\n# Define transformations if needed (e.g., resizing, normalization, etc.)\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(0,1)\n])\n\n\n\ndef get_datasets(train_images,val_images,train_labels,val_labels,test_labels,test_images):\n    #Create an instance of your custom dataset\n    custom_dataset_train = CustomDataset(train_images, train_labels, transform)\n\n    # Create a DataLoader to handle batching and shuffling\n    data_loader_train = torch.utils.data.DataLoader(custom_dataset_train, batch_size=1024, shuffle=True)\n\n    # Create an instance of your custom dataset\n    custom_dataset_val = CustomDataset(val_images, val_labels, transform)\n\n    # Create a DataLoader to handle batching and shuffling\n    data_loader_val = torch.utils.data.DataLoader(custom_dataset_val, batch_size=1024, shuffle=False)\n    \n    # Create an instance of your custom dataset\n    custom_dataset_test = CustomDataset(test_images, test_labels, transform)\n\n    # Create a DataLoader to handle batching and shuffling\n    data_loader_test = torch.utils.data.DataLoader(custom_dataset_test, batch_size=1024, shuffle=False)\n\n\n    return  data_loader_train, data_loader_val, data_loader_test\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-22T00:30:26.202355Z","iopub.execute_input":"2023-12-22T00:30:26.202653Z","iopub.status.idle":"2023-12-22T00:30:39.455380Z","shell.execute_reply.started":"2023-12-22T00:30:26.202626Z","shell.execute_reply":"2023-12-22T00:30:39.454357Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"train_images,val_images,train_labels,val_labels,train_labels_pt,val_labels_pt,test_images,test_labels,test_labels_pt = get_data()\nmodel = get_model()\ndataset_train,dataset_val,dataset_test = get_datasets(train_images,val_images,train_labels_pt,val_labels_pt,test_labels_pt,test_images)\nweights = class_weights(train_labels)\nweights.to(device)\ncriterion = get_criterion(weights)\ncriterion.to(device)\nmodel","metadata":{"execution":{"iopub.status.busy":"2023-12-22T00:30:39.456683Z","iopub.execute_input":"2023-12-22T00:30:39.457293Z","iopub.status.idle":"2023-12-22T00:35:18.724845Z","shell.execute_reply.started":"2023-12-22T00:30:39.457264Z","shell.execute_reply":"2023-12-22T00:35:18.723895Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"100%|██████████| 150653/150653 [04:31<00:00, 555.21it/s]\nDownloading: \"https://download.pytorch.org/models/mobilenet_v3_large-5c1a4163.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_large-5c1a4163.pth\n100%|██████████| 21.1M/21.1M [00:00<00:00, 135MB/s] \n","output_type":"stream"},{"name":"stdout","text":"features.0.0.weight: requires_grad=False\nfeatures.0.1.weight: requires_grad=False\nfeatures.0.1.bias: requires_grad=False\nfeatures.1.block.0.0.weight: requires_grad=False\nfeatures.1.block.0.1.weight: requires_grad=False\nfeatures.1.block.0.1.bias: requires_grad=False\nfeatures.1.block.1.0.weight: requires_grad=False\nfeatures.1.block.1.1.weight: requires_grad=False\nfeatures.1.block.1.1.bias: requires_grad=False\nfeatures.2.block.0.0.weight: requires_grad=False\nfeatures.2.block.0.1.weight: requires_grad=False\nfeatures.2.block.0.1.bias: requires_grad=False\nfeatures.2.block.1.0.weight: requires_grad=False\nfeatures.2.block.1.1.weight: requires_grad=False\nfeatures.2.block.1.1.bias: requires_grad=False\nfeatures.2.block.2.0.weight: requires_grad=False\nfeatures.2.block.2.1.weight: requires_grad=False\nfeatures.2.block.2.1.bias: requires_grad=False\nfeatures.3.block.0.0.weight: requires_grad=False\nfeatures.3.block.0.1.weight: requires_grad=False\nfeatures.3.block.0.1.bias: requires_grad=False\nfeatures.3.block.1.0.weight: requires_grad=False\nfeatures.3.block.1.1.weight: requires_grad=False\nfeatures.3.block.1.1.bias: requires_grad=False\nfeatures.3.block.2.0.weight: requires_grad=False\nfeatures.3.block.2.1.weight: requires_grad=False\nfeatures.3.block.2.1.bias: requires_grad=False\nfeatures.4.block.0.0.weight: requires_grad=False\nfeatures.4.block.0.1.weight: requires_grad=False\nfeatures.4.block.0.1.bias: requires_grad=False\nfeatures.4.block.1.0.weight: requires_grad=False\nfeatures.4.block.1.1.weight: requires_grad=False\nfeatures.4.block.1.1.bias: requires_grad=False\nfeatures.4.block.2.fc1.weight: requires_grad=False\nfeatures.4.block.2.fc1.bias: requires_grad=False\nfeatures.4.block.2.fc2.weight: requires_grad=False\nfeatures.4.block.2.fc2.bias: requires_grad=False\nfeatures.4.block.3.0.weight: requires_grad=False\nfeatures.4.block.3.1.weight: requires_grad=False\nfeatures.4.block.3.1.bias: requires_grad=False\nfeatures.5.block.0.0.weight: requires_grad=False\nfeatures.5.block.0.1.weight: requires_grad=False\nfeatures.5.block.0.1.bias: requires_grad=False\nfeatures.5.block.1.0.weight: requires_grad=False\nfeatures.5.block.1.1.weight: requires_grad=False\nfeatures.5.block.1.1.bias: requires_grad=False\nfeatures.5.block.2.fc1.weight: requires_grad=False\nfeatures.5.block.2.fc1.bias: requires_grad=False\nfeatures.5.block.2.fc2.weight: requires_grad=False\nfeatures.5.block.2.fc2.bias: requires_grad=False\nfeatures.5.block.3.0.weight: requires_grad=False\nfeatures.5.block.3.1.weight: requires_grad=False\nfeatures.5.block.3.1.bias: requires_grad=False\nfeatures.6.block.0.0.weight: requires_grad=False\nfeatures.6.block.0.1.weight: requires_grad=False\nfeatures.6.block.0.1.bias: requires_grad=False\nfeatures.6.block.1.0.weight: requires_grad=False\nfeatures.6.block.1.1.weight: requires_grad=False\nfeatures.6.block.1.1.bias: requires_grad=False\nfeatures.6.block.2.fc1.weight: requires_grad=False\nfeatures.6.block.2.fc1.bias: requires_grad=False\nfeatures.6.block.2.fc2.weight: requires_grad=False\nfeatures.6.block.2.fc2.bias: requires_grad=False\nfeatures.6.block.3.0.weight: requires_grad=False\nfeatures.6.block.3.1.weight: requires_grad=False\nfeatures.6.block.3.1.bias: requires_grad=False\nfeatures.7.block.0.0.weight: requires_grad=False\nfeatures.7.block.0.1.weight: requires_grad=False\nfeatures.7.block.0.1.bias: requires_grad=False\nfeatures.7.block.1.0.weight: requires_grad=False\nfeatures.7.block.1.1.weight: requires_grad=False\nfeatures.7.block.1.1.bias: requires_grad=False\nfeatures.7.block.2.0.weight: requires_grad=False\nfeatures.7.block.2.1.weight: requires_grad=False\nfeatures.7.block.2.1.bias: requires_grad=False\nfeatures.8.block.0.0.weight: requires_grad=False\nfeatures.8.block.0.1.weight: requires_grad=False\nfeatures.8.block.0.1.bias: requires_grad=False\nfeatures.8.block.1.0.weight: requires_grad=False\nfeatures.8.block.1.1.weight: requires_grad=False\nfeatures.8.block.1.1.bias: requires_grad=False\nfeatures.8.block.2.0.weight: requires_grad=False\nfeatures.8.block.2.1.weight: requires_grad=False\nfeatures.8.block.2.1.bias: requires_grad=False\nfeatures.9.block.0.0.weight: requires_grad=False\nfeatures.9.block.0.1.weight: requires_grad=False\nfeatures.9.block.0.1.bias: requires_grad=False\nfeatures.9.block.1.0.weight: requires_grad=False\nfeatures.9.block.1.1.weight: requires_grad=False\nfeatures.9.block.1.1.bias: requires_grad=False\nfeatures.9.block.2.0.weight: requires_grad=False\nfeatures.9.block.2.1.weight: requires_grad=False\nfeatures.9.block.2.1.bias: requires_grad=False\nfeatures.10.block.0.0.weight: requires_grad=False\nfeatures.10.block.0.1.weight: requires_grad=False\nfeatures.10.block.0.1.bias: requires_grad=False\nfeatures.10.block.1.0.weight: requires_grad=False\nfeatures.10.block.1.1.weight: requires_grad=False\nfeatures.10.block.1.1.bias: requires_grad=False\nfeatures.10.block.2.0.weight: requires_grad=False\nfeatures.10.block.2.1.weight: requires_grad=False\nfeatures.10.block.2.1.bias: requires_grad=False\nfeatures.11.block.0.0.weight: requires_grad=False\nfeatures.11.block.0.1.weight: requires_grad=False\nfeatures.11.block.0.1.bias: requires_grad=False\nfeatures.11.block.1.0.weight: requires_grad=False\nfeatures.11.block.1.1.weight: requires_grad=False\nfeatures.11.block.1.1.bias: requires_grad=False\nfeatures.11.block.2.fc1.weight: requires_grad=False\nfeatures.11.block.2.fc1.bias: requires_grad=False\nfeatures.11.block.2.fc2.weight: requires_grad=False\nfeatures.11.block.2.fc2.bias: requires_grad=False\nfeatures.11.block.3.0.weight: requires_grad=False\nfeatures.11.block.3.1.weight: requires_grad=False\nfeatures.11.block.3.1.bias: requires_grad=False\nfeatures.12.block.0.0.weight: requires_grad=False\nfeatures.12.block.0.1.weight: requires_grad=False\nfeatures.12.block.0.1.bias: requires_grad=False\nfeatures.12.block.1.0.weight: requires_grad=False\nfeatures.12.block.1.1.weight: requires_grad=False\nfeatures.12.block.1.1.bias: requires_grad=False\nfeatures.12.block.2.fc1.weight: requires_grad=False\nfeatures.12.block.2.fc1.bias: requires_grad=False\nfeatures.12.block.2.fc2.weight: requires_grad=False\nfeatures.12.block.2.fc2.bias: requires_grad=False\nfeatures.12.block.3.0.weight: requires_grad=False\nfeatures.12.block.3.1.weight: requires_grad=False\nfeatures.12.block.3.1.bias: requires_grad=False\nfeatures.13.block.0.0.weight: requires_grad=False\nfeatures.13.block.0.1.weight: requires_grad=False\nfeatures.13.block.0.1.bias: requires_grad=False\nfeatures.13.block.1.0.weight: requires_grad=False\nfeatures.13.block.1.1.weight: requires_grad=False\nfeatures.13.block.1.1.bias: requires_grad=False\nfeatures.13.block.2.fc1.weight: requires_grad=False\nfeatures.13.block.2.fc1.bias: requires_grad=False\nfeatures.13.block.2.fc2.weight: requires_grad=False\nfeatures.13.block.2.fc2.bias: requires_grad=False\nfeatures.13.block.3.0.weight: requires_grad=False\nfeatures.13.block.3.1.weight: requires_grad=False\nfeatures.13.block.3.1.bias: requires_grad=False\nfeatures.14.block.0.0.weight: requires_grad=False\nfeatures.14.block.0.1.weight: requires_grad=False\nfeatures.14.block.0.1.bias: requires_grad=False\nfeatures.14.block.1.0.weight: requires_grad=False\nfeatures.14.block.1.1.weight: requires_grad=False\nfeatures.14.block.1.1.bias: requires_grad=False\nfeatures.14.block.2.fc1.weight: requires_grad=False\nfeatures.14.block.2.fc1.bias: requires_grad=False\nfeatures.14.block.2.fc2.weight: requires_grad=False\nfeatures.14.block.2.fc2.bias: requires_grad=False\nfeatures.14.block.3.0.weight: requires_grad=False\nfeatures.14.block.3.1.weight: requires_grad=False\nfeatures.14.block.3.1.bias: requires_grad=False\nfeatures.15.block.0.0.weight: requires_grad=False\nfeatures.15.block.0.1.weight: requires_grad=False\nfeatures.15.block.0.1.bias: requires_grad=False\nfeatures.15.block.1.0.weight: requires_grad=False\nfeatures.15.block.1.1.weight: requires_grad=False\nfeatures.15.block.1.1.bias: requires_grad=False\nfeatures.15.block.2.fc1.weight: requires_grad=False\nfeatures.15.block.2.fc1.bias: requires_grad=False\nfeatures.15.block.2.fc2.weight: requires_grad=False\nfeatures.15.block.2.fc2.bias: requires_grad=False\nfeatures.15.block.3.0.weight: requires_grad=False\nfeatures.15.block.3.1.weight: requires_grad=False\nfeatures.15.block.3.1.bias: requires_grad=False\nfeatures.16.0.weight: requires_grad=True\nfeatures.16.1.weight: requires_grad=True\nfeatures.16.1.bias: requires_grad=True\nclassifier.0.weight: requires_grad=True\nclassifier.0.bias: requires_grad=True\nclassifier.3.weight: requires_grad=True\nclassifier.3.bias: requires_grad=True\n[(101, 3444), (67, 3186), (70, 3048), (24, 2456), (51, 1138), (22, 1018), (0, 1000), (1, 1000), (2, 1000), (3, 1000), (4, 1000), (5, 1000), (6, 1000), (7, 1000), (8, 1000), (9, 1000), (10, 1000), (11, 1000), (12, 1000), (13, 1000), (14, 1000), (15, 1000), (73, 1000), (84, 1000), (77, 1000), (88, 1000), (83, 1000), (74, 1000), (57, 1000), (59, 1000), (91, 1000), (34, 1000), (16, 1000), (28, 1000), (87, 1000), (42, 1000), (64, 1000), (97, 1000), (40, 1000), (33, 1000), (62, 1000), (41, 1000), (52, 1000), (17, 1000), (78, 1000), (32, 1000), (18, 1000), (31, 1000), (79, 1000), (90, 1000), (96, 1000), (43, 1000), (89, 1000), (55, 1000), (53, 1000), (60, 1000), (19, 1000), (75, 1000), (85, 1000), (65, 1000), (35, 1000), (20, 1000), (36, 1000), (81, 1000), (98, 1000), (63, 1000), (61, 1000), (21, 1000), (80, 1000), (72, 1000), (23, 1000), (25, 1000), (26, 1000), (27, 1000), (29, 1000), (30, 1000), (37, 1000), (38, 1000), (39, 1000), (44, 1000), (45, 1000), (46, 1000), (47, 1000), (48, 1000), (49, 1000), (50, 1000), (54, 1000), (56, 1000), (58, 1000), (66, 1000), (68, 1000), (69, 1000), (71, 1000), (76, 1000), (82, 1000), (86, 1000), (92, 1000), (93, 1000), (94, 1000), (95, 1000), (99, 1000), (100, 1000)]\ntensor([110.2900, 110.2900, 110.2900, 110.2900, 110.2900, 110.2900, 110.2900,\n        110.2900, 110.2900, 110.2900, 110.2900, 110.2900, 110.2900, 110.2900,\n        110.2900, 110.2900, 110.2900, 110.2900, 110.2900, 110.2900, 110.2900,\n        110.2900, 108.3399, 110.2900,  44.9064, 110.2900, 110.2900, 110.2900,\n        110.2900, 110.2900, 110.2900, 110.2900, 110.2900, 110.2900, 110.2900,\n        110.2900, 110.2900, 110.2900, 110.2900, 110.2900, 110.2900, 110.2900,\n        110.2900, 110.2900, 110.2900, 110.2900, 110.2900, 110.2900, 110.2900,\n        110.2900, 110.2900,  96.9156, 110.2900, 110.2900, 110.2900, 110.2900,\n        110.2900, 110.2900, 110.2900, 110.2900, 110.2900, 110.2900, 110.2900,\n        110.2900, 110.2900, 110.2900, 110.2900,  34.6171, 110.2900, 110.2900,\n         36.1844, 110.2900, 110.2900, 110.2900, 110.2900, 110.2900, 110.2900,\n        110.2900, 110.2900, 110.2900, 110.2900, 110.2900, 110.2900, 110.2900,\n        110.2900, 110.2900, 110.2900, 110.2900, 110.2900, 110.2900, 110.2900,\n        110.2900, 110.2900, 110.2900, 110.2900, 110.2900, 110.2900, 110.2900,\n        110.2900, 110.2900, 110.2900,  32.0238])\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"CustomModel(\n  (sota): MobileNetV3(\n    (features): Sequential(\n      (0): Conv2dNormActivation(\n        (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (2): Hardswish()\n      )\n      (1): InvertedResidual(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n            (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (2): InvertedResidual(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (2): Conv2dNormActivation(\n            (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (3): InvertedResidual(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (2): Conv2dNormActivation(\n            (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (4): InvertedResidual(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n            (activation): ReLU()\n            (scale_activation): Hardsigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (5): InvertedResidual(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n            (activation): ReLU()\n            (scale_activation): Hardsigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (6): InvertedResidual(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n            (activation): ReLU()\n            (scale_activation): Hardsigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (7): InvertedResidual(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): Hardswish()\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): Hardswish()\n          )\n          (2): Conv2dNormActivation(\n            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (8): InvertedResidual(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): Hardswish()\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n            (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): Hardswish()\n          )\n          (2): Conv2dNormActivation(\n            (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (9): InvertedResidual(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): Hardswish()\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n            (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): Hardswish()\n          )\n          (2): Conv2dNormActivation(\n            (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (10): InvertedResidual(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): Hardswish()\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n            (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): Hardswish()\n          )\n          (2): Conv2dNormActivation(\n            (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (11): InvertedResidual(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): Hardswish()\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): Hardswish()\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n            (activation): ReLU()\n            (scale_activation): Hardsigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (12): InvertedResidual(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): Hardswish()\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n            (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): Hardswish()\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n            (activation): ReLU()\n            (scale_activation): Hardsigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (13): InvertedResidual(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): Hardswish()\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n            (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): Hardswish()\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n            (activation): ReLU()\n            (scale_activation): Hardsigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (14): InvertedResidual(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): Hardswish()\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): Hardswish()\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n            (activation): ReLU()\n            (scale_activation): Hardsigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (15): InvertedResidual(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): Hardswish()\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): Hardswish()\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n            (activation): ReLU()\n            (scale_activation): Hardsigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (16): Conv2dNormActivation(\n        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (2): Hardswish()\n      )\n    )\n    (avgpool): AdaptiveAvgPool2d(output_size=1)\n    (classifier): Sequential(\n      (0): Linear(in_features=960, out_features=1280, bias=True)\n      (1): Hardswish()\n      (2): Dropout(p=0.2, inplace=True)\n      (3): Linear(in_features=1280, out_features=102, bias=True)\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"dataset_test.batch_size","metadata":{"execution":{"iopub.status.busy":"2023-12-22T00:35:18.726124Z","iopub.execute_input":"2023-12-22T00:35:18.726434Z","iopub.status.idle":"2023-12-22T00:35:18.732771Z","shell.execute_reply.started":"2023-12-22T00:35:18.726407Z","shell.execute_reply":"2023-12-22T00:35:18.731608Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"1024"},"metadata":{}}]},{"cell_type":"code","source":"model.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-12-22T00:35:18.734013Z","iopub.execute_input":"2023-12-22T00:35:18.734267Z","iopub.status.idle":"2023-12-22T00:35:18.772481Z","shell.execute_reply.started":"2023-12-22T00:35:18.734245Z","shell.execute_reply":"2023-12-22T00:35:18.771471Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"CustomModel(\n  (sota): MobileNetV3(\n    (features): Sequential(\n      (0): Conv2dNormActivation(\n        (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (2): Hardswish()\n      )\n      (1): InvertedResidual(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n            (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (2): InvertedResidual(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (2): Conv2dNormActivation(\n            (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (3): InvertedResidual(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (2): Conv2dNormActivation(\n            (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (4): InvertedResidual(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n            (activation): ReLU()\n            (scale_activation): Hardsigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (5): InvertedResidual(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n            (activation): ReLU()\n            (scale_activation): Hardsigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (6): InvertedResidual(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n            (activation): ReLU()\n            (scale_activation): Hardsigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (7): InvertedResidual(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): Hardswish()\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): Hardswish()\n          )\n          (2): Conv2dNormActivation(\n            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (8): InvertedResidual(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): Hardswish()\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n            (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): Hardswish()\n          )\n          (2): Conv2dNormActivation(\n            (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (9): InvertedResidual(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): Hardswish()\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n            (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): Hardswish()\n          )\n          (2): Conv2dNormActivation(\n            (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (10): InvertedResidual(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): Hardswish()\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n            (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): Hardswish()\n          )\n          (2): Conv2dNormActivation(\n            (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (11): InvertedResidual(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): Hardswish()\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): Hardswish()\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n            (activation): ReLU()\n            (scale_activation): Hardsigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (12): InvertedResidual(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): Hardswish()\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n            (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): Hardswish()\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n            (activation): ReLU()\n            (scale_activation): Hardsigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (13): InvertedResidual(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): Hardswish()\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n            (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): Hardswish()\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n            (activation): ReLU()\n            (scale_activation): Hardsigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (14): InvertedResidual(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): Hardswish()\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): Hardswish()\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n            (activation): ReLU()\n            (scale_activation): Hardsigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (15): InvertedResidual(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): Hardswish()\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n            (2): Hardswish()\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n            (activation): ReLU()\n            (scale_activation): Hardsigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n          )\n        )\n      )\n      (16): Conv2dNormActivation(\n        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n        (2): Hardswish()\n      )\n    )\n    (avgpool): AdaptiveAvgPool2d(output_size=1)\n    (classifier): Sequential(\n      (0): Linear(in_features=960, out_features=1280, bias=True)\n      (1): Hardswish()\n      (2): Dropout(p=0.2, inplace=True)\n      (3): Linear(in_features=1280, out_features=102, bias=True)\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"import torchvision.models as models\nimport torch.nn as nn\nimport torch.optim as optim\nfrom tqdm import auto\noptimizer = optim.AdamW([\n    {'params': model.sota.classifier.parameters()},\n    {'params': model.sota.features[16].parameters(), 'lr': 0.001}\n], lr=0.01, weight_decay=0.06)\n\nnum_epochs = 20\nprogress_bar = tqdm(range(len(dataset_train)*num_epochs))\n# lambda1 = lambda epoch: 0.95 ** epoch\n# scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)\n# scheduler2 = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,mode='min',factor=0.2,patience=2,min_lr=0.0001)","metadata":{"execution":{"iopub.status.busy":"2023-12-22T00:47:36.830491Z","iopub.execute_input":"2023-12-22T00:47:36.831005Z","iopub.status.idle":"2023-12-22T00:47:36.841390Z","shell.execute_reply.started":"2023-12-22T00:47:36.830971Z","shell.execute_reply":"2023-12-22T00:47:36.840179Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"  0%|          | 0/2160 [00:00<?, ?it/s]","output_type":"stream"}]},{"cell_type":"code","source":"def save_checkpoint(model,step_num):\n        torch.save(model.state_dict(), f\"/kaggle/working/mobilenetv3_large_checkpoints/mobilenetv3_large_checkpoint_{step_num}.pt\")\n        print(f\"Checkpoint saved at step {step_num}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-22T00:47:39.351473Z","iopub.execute_input":"2023-12-22T00:47:39.351925Z","iopub.status.idle":"2023-12-22T00:47:39.357007Z","shell.execute_reply.started":"2023-12-22T00:47:39.351891Z","shell.execute_reply":"2023-12-22T00:47:39.356067Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from torcheval.metrics import MulticlassAUPRC\ndef evaluate(data_loader,model):\n  model.eval()\n  data_loader.shuffle=False\n  torch.cuda.empty_cache()\n  ap = MulticlassAUPRC(num_classes=102)\n  ap_per_class = MulticlassAUPRC(num_classes=102, average=None)\n  no_correct,no_samples = 0,0\n  total_loss = 0\n  total_ap = 0\n  total_ap_per_class = torch.zeros(102)\n  \n  with torch.no_grad():\n    for images_val,labels_val in data_loader:\n     \n      images_val = images_val.to(device)\n      labels_val = labels_val.to(device)\n      outputs = model(images_val)\n      loss = criterion(outputs,labels_val)\n        \n      _, predictions = torch.max(outputs, 1)\n      no_correct += (predictions == labels_val).sum().item()\n      no_samples += labels_val.size(0)\n      total_loss += loss\n      ap.update(outputs,labels_val)\n      ap_per_class.update(outputs,labels_val)\n      total_ap += ap.compute()\n      total_ap_per_class += ap_per_class.compute()\n    \n    accuracy = no_correct/no_samples\n    total_loss = total_loss/len(data_loader)\n    total_ap /= len(data_loader)\n    total_ap_per_class /= len(data_loader)\n    \n    data_loader.shuffle= True\n    return accuracy,total_loss,total_ap,total_ap_per_class\n","metadata":{"execution":{"iopub.status.busy":"2023-12-22T00:47:40.300067Z","iopub.execute_input":"2023-12-22T00:47:40.300479Z","iopub.status.idle":"2023-12-22T00:47:40.594664Z","shell.execute_reply.started":"2023-12-22T00:47:40.300447Z","shell.execute_reply":"2023-12-22T00:47:40.593564Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def freeze_layer(model):\n    for name, param in model.sota.named_parameters():\n        if name.startswith('features.16') :\n            param.requires_grad = False\n    for name, param in model.sota.named_parameters():\n        print(f'name: {name} ; requires_grad= {param.requires_grad}')\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-12-22T00:47:41.085575Z","iopub.execute_input":"2023-12-22T00:47:41.086438Z","iopub.status.idle":"2023-12-22T00:47:41.092118Z","shell.execute_reply.started":"2023-12-22T00:47:41.086402Z","shell.execute_reply":"2023-12-22T00:47:41.091013Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import os\n\n# Define the directory path\ndirectory_path = '/kaggle/working/mobilenetv3_large_checkpoints'\n\n# Check if the directory exists, and if not, create it\nif not os.path.exists(directory_path):\n    os.makedirs(directory_path)\n\n# Now you can proceed with your operations related to the directory\n","metadata":{"execution":{"iopub.status.busy":"2023-12-22T00:47:41.769459Z","iopub.execute_input":"2023-12-22T00:47:41.769860Z","iopub.status.idle":"2023-12-22T00:47:41.775810Z","shell.execute_reply.started":"2023-12-22T00:47:41.769800Z","shell.execute_reply":"2023-12-22T00:47:41.774874Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def train(epoch_to_freeze,save_steps,print_steps,scheduler,model,dataset_train,dataset_val):\n    global progress_bar\n    import torch\n    from torcheval.metrics import MulticlassAUPRC\n    metric = MulticlassAUPRC(num_classes=102)\n    scaler = torch.cuda.amp.GradScaler()\n    try:\n        for epoch in range(num_epochs):\n          if epoch == epoch_to_freeze:\n              model = freeze_layer(model)\n          torch.cuda.empty_cache()\n          for images, labels in dataset_train:\n                model.train()\n                images = images.to(device)\n                labels = labels.to(device)\n                optimizer.zero_grad()\n                with torch.autocast(device_type='cuda', dtype=torch.float16):\n                    outputs = model(images)\n                    loss = criterion(outputs, labels)\n                scaler.scale(loss).backward()\n                scaler.step(optimizer)\n                scaler.update()\n\n\n\n                if progress_bar.n % print_steps == 0:\n                    _, predictions = torch.max(outputs, 1)\n                    no_correct = (predictions == labels).sum().item()\n                    no_samples = labels.size(0)\n                    accuracy = no_correct/no_samples\n                    metric.update(outputs,labels)\n                    ap = metric.compute()\n                    print(f'Step: {progress_bar.n} Loss: {round(loss.item(),4)} Accuracy for train batch: {accuracy} AP: {ap}')\n\n                if progress_bar.n % save_steps == 0 and progress_bar.n != 0:\n                    save_checkpoint(model,progress_bar.n)\n\n                progress_bar.update(1)\n\n          # evaluation after each epoch\n          model.eval()\n          accuracy_train,loss_train,ap_t,ap_pct = evaluate(dataset_train,model)\n\n          print(f'Epoch {epoch + 1}/{num_epochs} Accuracy for training: {accuracy_train} Loss for training: {loss_train} Average Precision Per Class: {ap_pct}')\n          print(f'Mean Average Precision: {ap_t}')\n\n          accuracy_val,loss_val,ap,ap_pc = evaluate(dataset_val,model)\n          if accuracy_val > 0.99:\n            save_checkpoint(model,progress_bar.n)\n            break\n          scheduler.step(round(loss_val.item(),2))\n          print(f'Epoch {epoch + 1}/{num_epochs} Accuracy for validation: {accuracy_val} Loss for validation: {loss_val} Average Precision Per Class: {ap_pc}')\n          print(f'Mean Average Precision: {ap}')\n\n    except KeyboardInterrupt as e:\n        save_checkpoint(model,progress_bar.n)","metadata":{"execution":{"iopub.status.busy":"2023-12-22T00:47:42.417102Z","iopub.execute_input":"2023-12-22T00:47:42.417456Z","iopub.status.idle":"2023-12-22T00:47:42.434187Z","shell.execute_reply.started":"2023-12-22T00:47:42.417428Z","shell.execute_reply":"2023-12-22T00:47:42.432902Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train(1,540,27,scheduler,model,dataset_train,dataset_val)","metadata":{"execution":{"iopub.status.busy":"2023-12-22T00:47:43.093351Z","iopub.execute_input":"2023-12-22T00:47:43.093725Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"  0%|          | 1/2160 [00:20<12:11:54, 20.34s/it]","output_type":"stream"},{"name":"stdout","text":"Step: 0 Loss: 4.6902 Accuracy for train batch: 0.015625 AP: 0.01874570921063423\n","output_type":"stream"},{"name":"stderr","text":"  1%|▏         | 28/2160 [03:42<4:23:47,  7.42s/it]","output_type":"stream"},{"name":"stdout","text":"Step: 27 Loss: 3.5847 Accuracy for train batch: 0.404296875 AP: 0.19655732810497284\n","output_type":"stream"},{"name":"stderr","text":"  3%|▎         | 55/2160 [07:04<4:34:27,  7.82s/it]","output_type":"stream"},{"name":"stdout","text":"Step: 54 Loss: 3.3315 Accuracy for train batch: 0.53515625 AP: 0.27687346935272217\n","output_type":"stream"},{"name":"stderr","text":"  4%|▍         | 82/2160 [10:22<4:16:57,  7.42s/it]","output_type":"stream"},{"name":"stdout","text":"Step: 81 Loss: 3.1982 Accuracy for train batch: 0.5859375 AP: 0.3320554792881012\n","output_type":"stream"},{"name":"stderr","text":"  5%|▌         | 108/2160 [13:51<4:03:51,  7.13s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20 Accuracy for training: 0.6145797443104543 Loss for training: 3.102942943572998 Average Precision Per Class: tensor([0.4162, 0.2581, 0.3503, 0.3065, 0.5313, 0.5670, 0.4861, 0.2751, 0.2731,\n        0.3635, 0.4505, 0.4011, 0.6512, 0.4303, 0.8009, 0.8768, 0.7350, 0.5504,\n        0.2818, 0.3291, 0.3158, 0.5746, 0.4350, 0.3012, 0.4325, 0.8397, 0.6627,\n        0.2397, 0.4204, 0.2376, 0.7494, 0.6136, 0.4882, 0.5790, 0.5934, 0.6436,\n        0.6624, 0.6057, 0.2150, 0.1769, 0.4992, 0.5960, 0.5532, 0.8698, 0.3636,\n        0.2145, 0.2521, 0.3848, 0.7393, 0.5404, 0.5670, 0.4900, 0.3098, 0.7711,\n        0.1414, 0.5954, 0.9488, 0.4737, 0.7262, 0.6347, 0.6517, 0.8455, 0.9308,\n        0.5031, 0.6087, 0.4652, 0.6552, 0.7131, 0.6561, 0.4841, 0.5404, 0.6678,\n        0.6263, 0.9041, 0.7207, 0.8395, 0.5619, 0.6228, 0.8224, 0.7443, 0.9032,\n        0.6550, 0.7755, 0.6715, 0.5648, 0.5010, 0.2710, 0.7540, 0.6903, 0.5360,\n        0.5196, 0.5839, 0.4150, 0.3584, 0.6899, 0.6618, 0.6696, 0.6053, 0.6086,\n        0.5912, 0.5643, 0.7217])\nMean Average Precision: 0.5555591583251953\nEpoch 1/20 Accuracy for validation: 0.4792042380522994 Loss for validation: 3.6673593521118164 Average Precision Per Class: tensor([0.4202, 0.1542, 0.2524, 0.3144, 0.5381, 0.5071, 0.2694, 0.2786, 0.2719,\n        0.2207, 0.4082, 0.2926, 0.2883, 0.1527, 0.7365, 0.9149, 0.6678, 0.2720,\n        0.2334, 0.1580, 0.2154, 0.4399, 0.3499, 0.2265, 0.5612, 0.5770, 0.3822,\n        0.2625, 0.0895, 0.1435, 0.4193, 0.2129, 0.2068, 0.2463, 0.2955, 0.1219,\n        0.1064, 0.4529, 0.1719, 0.0420, 0.2252, 0.2721, 0.2912, 0.2296, 0.1737,\n        0.0700, 0.2590, 0.3971, 0.3249, 0.4202, 0.4644, 0.1182, 0.0535, 0.2635,\n        0.0857, 0.2015, 0.6759, 0.1531, 0.3182, 0.3619, 0.1622, 0.2649, 0.4936,\n        0.0611, 0.2414, 0.1336, 0.4588, 0.1613, 0.4197, 0.2870, 0.0913, 0.4438,\n        0.2231, 0.6520, 0.3549, 0.3435, 0.4531, 0.4764, 0.3566, 0.3388, 0.2365,\n        0.0963, 0.5125, 0.4853, 0.3895, 0.1310, 0.0778, 0.4176, 0.3390, 0.2298,\n        0.0999, 0.3490, 0.2409, 0.1176, 0.5021, 0.4141, 0.3004, 0.1271, 0.2439,\n        0.4894, 0.3528, 0.0671])\nMean Average Precision: 0.3026481866836548\nname: features.0.0.weight ; requires_grad= False\nname: features.0.1.weight ; requires_grad= False\nname: features.0.1.bias ; requires_grad= False\nname: features.1.block.0.0.weight ; requires_grad= False\nname: features.1.block.0.1.weight ; requires_grad= False\nname: features.1.block.0.1.bias ; requires_grad= False\nname: features.1.block.1.0.weight ; requires_grad= False\nname: features.1.block.1.1.weight ; requires_grad= False\nname: features.1.block.1.1.bias ; requires_grad= False\nname: features.2.block.0.0.weight ; requires_grad= False\nname: features.2.block.0.1.weight ; requires_grad= False\nname: features.2.block.0.1.bias ; requires_grad= False\nname: features.2.block.1.0.weight ; requires_grad= False\nname: features.2.block.1.1.weight ; requires_grad= False\nname: features.2.block.1.1.bias ; requires_grad= False\nname: features.2.block.2.0.weight ; requires_grad= False\nname: features.2.block.2.1.weight ; requires_grad= False\nname: features.2.block.2.1.bias ; requires_grad= False\nname: features.3.block.0.0.weight ; requires_grad= False\nname: features.3.block.0.1.weight ; requires_grad= False\nname: features.3.block.0.1.bias ; requires_grad= False\nname: features.3.block.1.0.weight ; requires_grad= False\nname: features.3.block.1.1.weight ; requires_grad= False\nname: features.3.block.1.1.bias ; requires_grad= False\nname: features.3.block.2.0.weight ; requires_grad= False\nname: features.3.block.2.1.weight ; requires_grad= False\nname: features.3.block.2.1.bias ; requires_grad= False\nname: features.4.block.0.0.weight ; requires_grad= False\nname: features.4.block.0.1.weight ; requires_grad= False\nname: features.4.block.0.1.bias ; requires_grad= False\nname: features.4.block.1.0.weight ; requires_grad= False\nname: features.4.block.1.1.weight ; requires_grad= False\nname: features.4.block.1.1.bias ; requires_grad= False\nname: features.4.block.2.fc1.weight ; requires_grad= False\nname: features.4.block.2.fc1.bias ; requires_grad= False\nname: features.4.block.2.fc2.weight ; requires_grad= False\nname: features.4.block.2.fc2.bias ; requires_grad= False\nname: features.4.block.3.0.weight ; requires_grad= False\nname: features.4.block.3.1.weight ; requires_grad= False\nname: features.4.block.3.1.bias ; requires_grad= False\nname: features.5.block.0.0.weight ; requires_grad= False\nname: features.5.block.0.1.weight ; requires_grad= False\nname: features.5.block.0.1.bias ; requires_grad= False\nname: features.5.block.1.0.weight ; requires_grad= False\nname: features.5.block.1.1.weight ; requires_grad= False\nname: features.5.block.1.1.bias ; requires_grad= False\nname: features.5.block.2.fc1.weight ; requires_grad= False\nname: features.5.block.2.fc1.bias ; requires_grad= False\nname: features.5.block.2.fc2.weight ; requires_grad= False\nname: features.5.block.2.fc2.bias ; requires_grad= False\nname: features.5.block.3.0.weight ; requires_grad= False\nname: features.5.block.3.1.weight ; requires_grad= False\nname: features.5.block.3.1.bias ; requires_grad= False\nname: features.6.block.0.0.weight ; requires_grad= False\nname: features.6.block.0.1.weight ; requires_grad= False\nname: features.6.block.0.1.bias ; requires_grad= False\nname: features.6.block.1.0.weight ; requires_grad= False\nname: features.6.block.1.1.weight ; requires_grad= False\nname: features.6.block.1.1.bias ; requires_grad= False\nname: features.6.block.2.fc1.weight ; requires_grad= False\nname: features.6.block.2.fc1.bias ; requires_grad= False\nname: features.6.block.2.fc2.weight ; requires_grad= False\nname: features.6.block.2.fc2.bias ; requires_grad= False\nname: features.6.block.3.0.weight ; requires_grad= False\nname: features.6.block.3.1.weight ; requires_grad= False\nname: features.6.block.3.1.bias ; requires_grad= False\nname: features.7.block.0.0.weight ; requires_grad= False\nname: features.7.block.0.1.weight ; requires_grad= False\nname: features.7.block.0.1.bias ; requires_grad= False\nname: features.7.block.1.0.weight ; requires_grad= False\nname: features.7.block.1.1.weight ; requires_grad= False\nname: features.7.block.1.1.bias ; requires_grad= False\nname: features.7.block.2.0.weight ; requires_grad= False\nname: features.7.block.2.1.weight ; requires_grad= False\nname: features.7.block.2.1.bias ; requires_grad= False\nname: features.8.block.0.0.weight ; requires_grad= False\nname: features.8.block.0.1.weight ; requires_grad= False\nname: features.8.block.0.1.bias ; requires_grad= False\nname: features.8.block.1.0.weight ; requires_grad= False\nname: features.8.block.1.1.weight ; requires_grad= False\nname: features.8.block.1.1.bias ; requires_grad= False\nname: features.8.block.2.0.weight ; requires_grad= False\nname: features.8.block.2.1.weight ; requires_grad= False\nname: features.8.block.2.1.bias ; requires_grad= False\nname: features.9.block.0.0.weight ; requires_grad= False\nname: features.9.block.0.1.weight ; requires_grad= False\nname: features.9.block.0.1.bias ; requires_grad= False\nname: features.9.block.1.0.weight ; requires_grad= False\nname: features.9.block.1.1.weight ; requires_grad= False\nname: features.9.block.1.1.bias ; requires_grad= False\nname: features.9.block.2.0.weight ; requires_grad= False\nname: features.9.block.2.1.weight ; requires_grad= False\nname: features.9.block.2.1.bias ; requires_grad= False\nname: features.10.block.0.0.weight ; requires_grad= False\nname: features.10.block.0.1.weight ; requires_grad= False\nname: features.10.block.0.1.bias ; requires_grad= False\nname: features.10.block.1.0.weight ; requires_grad= False\nname: features.10.block.1.1.weight ; requires_grad= False\nname: features.10.block.1.1.bias ; requires_grad= False\nname: features.10.block.2.0.weight ; requires_grad= False\nname: features.10.block.2.1.weight ; requires_grad= False\nname: features.10.block.2.1.bias ; requires_grad= False\nname: features.11.block.0.0.weight ; requires_grad= False\nname: features.11.block.0.1.weight ; requires_grad= False\nname: features.11.block.0.1.bias ; requires_grad= False\nname: features.11.block.1.0.weight ; requires_grad= False\nname: features.11.block.1.1.weight ; requires_grad= False\nname: features.11.block.1.1.bias ; requires_grad= False\nname: features.11.block.2.fc1.weight ; requires_grad= False\nname: features.11.block.2.fc1.bias ; requires_grad= False\nname: features.11.block.2.fc2.weight ; requires_grad= False\nname: features.11.block.2.fc2.bias ; requires_grad= False\nname: features.11.block.3.0.weight ; requires_grad= False\nname: features.11.block.3.1.weight ; requires_grad= False\nname: features.11.block.3.1.bias ; requires_grad= False\nname: features.12.block.0.0.weight ; requires_grad= False\nname: features.12.block.0.1.weight ; requires_grad= False\nname: features.12.block.0.1.bias ; requires_grad= False\nname: features.12.block.1.0.weight ; requires_grad= False\nname: features.12.block.1.1.weight ; requires_grad= False\nname: features.12.block.1.1.bias ; requires_grad= False\nname: features.12.block.2.fc1.weight ; requires_grad= False\nname: features.12.block.2.fc1.bias ; requires_grad= False\nname: features.12.block.2.fc2.weight ; requires_grad= False\nname: features.12.block.2.fc2.bias ; requires_grad= False\nname: features.12.block.3.0.weight ; requires_grad= False\nname: features.12.block.3.1.weight ; requires_grad= False\nname: features.12.block.3.1.bias ; requires_grad= False\nname: features.13.block.0.0.weight ; requires_grad= False\nname: features.13.block.0.1.weight ; requires_grad= False\nname: features.13.block.0.1.bias ; requires_grad= False\nname: features.13.block.1.0.weight ; requires_grad= False\nname: features.13.block.1.1.weight ; requires_grad= False\nname: features.13.block.1.1.bias ; requires_grad= False\nname: features.13.block.2.fc1.weight ; requires_grad= False\nname: features.13.block.2.fc1.bias ; requires_grad= False\nname: features.13.block.2.fc2.weight ; requires_grad= False\nname: features.13.block.2.fc2.bias ; requires_grad= False\nname: features.13.block.3.0.weight ; requires_grad= False\nname: features.13.block.3.1.weight ; requires_grad= False\nname: features.13.block.3.1.bias ; requires_grad= False\nname: features.14.block.0.0.weight ; requires_grad= False\nname: features.14.block.0.1.weight ; requires_grad= False\nname: features.14.block.0.1.bias ; requires_grad= False\nname: features.14.block.1.0.weight ; requires_grad= False\nname: features.14.block.1.1.weight ; requires_grad= False\nname: features.14.block.1.1.bias ; requires_grad= False\nname: features.14.block.2.fc1.weight ; requires_grad= False\nname: features.14.block.2.fc1.bias ; requires_grad= False\nname: features.14.block.2.fc2.weight ; requires_grad= False\nname: features.14.block.2.fc2.bias ; requires_grad= False\nname: features.14.block.3.0.weight ; requires_grad= False\nname: features.14.block.3.1.weight ; requires_grad= False\nname: features.14.block.3.1.bias ; requires_grad= False\nname: features.15.block.0.0.weight ; requires_grad= False\nname: features.15.block.0.1.weight ; requires_grad= False\nname: features.15.block.0.1.bias ; requires_grad= False\nname: features.15.block.1.0.weight ; requires_grad= False\nname: features.15.block.1.1.weight ; requires_grad= False\nname: features.15.block.1.1.bias ; requires_grad= False\nname: features.15.block.2.fc1.weight ; requires_grad= False\nname: features.15.block.2.fc1.bias ; requires_grad= False\nname: features.15.block.2.fc2.weight ; requires_grad= False\nname: features.15.block.2.fc2.bias ; requires_grad= False\nname: features.15.block.3.0.weight ; requires_grad= False\nname: features.15.block.3.1.weight ; requires_grad= False\nname: features.15.block.3.1.bias ; requires_grad= False\nname: features.16.0.weight ; requires_grad= False\nname: features.16.1.weight ; requires_grad= False\nname: features.16.1.bias ; requires_grad= False\nname: classifier.0.weight ; requires_grad= True\nname: classifier.0.bias ; requires_grad= True\nname: classifier.3.weight ; requires_grad= True\nname: classifier.3.bias ; requires_grad= True\n","output_type":"stream"},{"name":"stderr","text":"  5%|▌         | 109/2160 [27:56<147:22:10, 258.67s/it]","output_type":"stream"},{"name":"stdout","text":"Step: 108 Loss: 2.8784 Accuracy for train batch: 0.7294921875 AP: 0.40050429105758667\n","output_type":"stream"},{"name":"stderr","text":"  6%|▌         | 129/2160 [29:29<2:46:16,  4.91s/it]   ","output_type":"stream"}]},{"cell_type":"code","source":"accuracy_val,loss_val,ap,ap_pc = evaluate(dataset_test,model)","metadata":{"execution":{"iopub.status.busy":"2023-12-21T20:16:44.897317Z","iopub.execute_input":"2023-12-21T20:16:44.897715Z","iopub.status.idle":"2023-12-21T20:22:17.089771Z","shell.execute_reply.started":"2023-12-21T20:16:44.897684Z","shell.execute_reply":"2023-12-21T20:22:17.088691Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"accuracy_val,loss_val,ap","metadata":{"execution":{"iopub.status.busy":"2023-12-21T20:22:17.092098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ap_pc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}